# app.py

import requests
from bs4 import BeautifulSoup
import time
import json

from utils.utils import save_to_excel, save_to_json

# --- ê¸°ëŠ¥ í•¨ìˆ˜ 1: ëª¨ë“  ë¶€ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ---
def get_smc_departments(headers):
    """ì‚¼ì„±ì„œìš¸ë³‘ì›ì—ì„œ ëª¨ë“  ë¶€ì„œì˜ ì´ë¦„ê³¼ ì½”ë“œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    group_codes = [{'type': 'O', 'name': 'ì§„ë£Œê³¼'}, {'type': 'C', 'name': 'ì„¼í„°'}, {'type': 'N', 'name': 'í´ë¦¬ë‹‰'}]
    base_url = "https://www.samsunghospital.com/home/reservation/DoctorScheduleGubun.do"
    all_departments = []
    
    print("1ë‹¨ê³„: ì „ì²´ ë¶€ì„œ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    for group in group_codes:
        print(f"  - ê·¸ë£¹ '{group['name']}({group['type']})' ëª©ë¡ ìˆ˜ì§‘ ì¤‘...")
        params = {'dp_type': group['type'], '_': int(time.time() * 1000)}
        try:
            response = requests.get(base_url, params=params, headers=headers)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            for option in soup.select('option'):
                if dept_code := option.get('value'):
                    all_departments.append({
                        'group_name': group['name'], 'group_code': group['type'],
                        'dept_name': option.get_text(strip=True), 'dept_code': dept_code
                    })
            time.sleep(0.3)
        except Exception as e:
            print(f"  - ìš”ì²­ ì‹¤íŒ¨ (ê·¸ë£¹: {group['type']}): {e}")
    return all_departments

# --- ê¸°ëŠ¥ í•¨ìˆ˜ 2: íŠ¹ì • ë¶€ì„œì˜ ì˜ë£Œì§„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìµœì¢… ìˆ˜ì •) ---
def get_smc_doctors_by_dept(headers, department):
    """ì£¼ì–´ì§„ ë¶€ì„œì˜ ì˜ë£Œì§„ ëª©ë¡ HTMLì„ íŒŒì‹±í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    base_url = "https://www.samsunghospital.com/home/reservation/doctorInfoLists.do"
    params = {'cPage': 1, 'DP_CODE': department['dept_code'], 'DP_TYPE': department['group_code'], '_': int(time.time() * 1000)}
    try:
        response = requests.get(base_url, params=params, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        doctors_in_dept = []
        for item in soup.select('ul.masonry li.card-item.doctor-profile'):
            name_tag = item.select_one('span[name="fullName"]')
            name = name_tag.get_text(strip=True) if name_tag else ''
            
            # h3 íƒœê·¸ì—ì„œ ì§ìœ„ì™€ ì†Œì†ê³¼ ì¶”ì¶œ
            title_tag = item.select_one('h3.card-content-title')
            full_title_text = title_tag.get_text(strip=True) if title_tag else ''
            position = full_title_text.replace(name, '').split('[')[0].strip()
            
            # --- ğŸ‘‡ ë„¤ê°€ ì•Œë ¤ì¤€ 'ì§„ë£Œë¶„ì•¼' ì„ íƒì ì •í™•í•˜ê²Œ ë°˜ì˜ ---
            fields_tag = item.select_one('p.card-content-text')
            fields = fields_tag.get_text(strip=True) if fields_tag else ''
            
            img_tag = item.select_one('div.card-content-img img')
            img_url = f"https://www.samsunghospital.com{img_tag['src']}" if img_tag and img_tag.has_attr('src') else ''

            link_tag = item.select_one('section.card-item-inner > a')
            detail_url = f"https://www.samsunghospital.com{link_tag['href']}" if link_tag and link_tag.has_attr('href') else ''

            doctors_in_dept.append({
                "ì†Œì†": department['dept_name'],
                "ì´ë¦„": name,
                "ì§ìœ„": position,
                "ì§„ë£Œë¶„ì•¼": fields,
                "ì´ë¯¸ì§€URL": img_url,
                "ìƒì„¸ì •ë³´URL": detail_url
            })
        return doctors_in_dept
    except Exception as e:
        print(f"    - {department['dept_name']} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        return []

# --- ê¸°ëŠ¥ í•¨ìˆ˜ 3: ì˜ë£Œì§„ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (í•™ë ¥/ê²½ë ¥) ---
def get_doctor_profile(detail_url, headers):
    """ìƒì„¸ í˜ì´ì§€ URLì„ ë°›ì•„ í•™ë ¥/ê²½ë ¥ ì •ë³´ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤."""
    if not detail_url:
        return {}
    try:
        response = requests.get(detail_url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        profile_data = {}
        for title_tag in soup.select('h2.doctor-paper-career-title'):
            title = title_tag.get_text(strip=True)
            if title in ['í•™ë ¥', 'ê²½ë ¥']:
                table_div = title_tag.find_next_sibling('div', class_='table-wrapper')
                if table_div:
                    records = []
                    for row in table_div.select('tbody tr'):
                        date = row.select_one('th').get_text(strip=True)
                        content = row.select_one('td').get_text(strip=True)
                        records.append(f"{date} {content}")
                    profile_data[title] = records
        return profile_data
    except Exception as e:
        print(f"      - ìƒì„¸ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        return {}

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
        'Referer': 'https://www.samsunghospital.com/home/reservation/deptAndDr.do',
        'X-Requested-With': 'XMLHttpRequest'
    }
    
    departments = get_smc_departments(headers)
    if not departments:
        print("\nâŒ 1ë‹¨ê³„ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        print(f"\nâœ… 1ë‹¨ê³„ ì™„ë£Œ: ì´ {len(departments)}ê°œ ë¶€ì„œ ìˆ˜ì§‘.")
        all_doctors = []
        print("\n2ë‹¨ê³„: ê° ë¶€ì„œë³„ ì˜ë£Œì§„ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘...")
        for i, dept in enumerate(departments):
            print(f"  - ({i+1}/{len(departments)}) {dept['dept_name']} ìˆ˜ì§‘ ì¤‘...")
            doctors = get_smc_doctors_by_dept(headers, dept)
            if doctors:
                all_doctors.extend(doctors)
            time.sleep(0.2)
        
        print(f"\nâœ… 2ë‹¨ê³„ ì™„ë£Œ: ì´ {len(all_doctors)}ëª… ì˜ë£Œì§„ ëª©ë¡ ìˆ˜ì§‘.")

        print("\n3ë‹¨ê³„: ê° ì˜ë£Œì§„ì˜ ìƒì„¸ í”„ë¡œí•„(í•™ë ¥/ê²½ë ¥) ìˆ˜ì§‘ ì‹œì‘...")
        for i, doctor in enumerate(all_doctors):
            print(f"  - ({i+1}/{len(all_doctors)}) {doctor['ì´ë¦„']} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
            profile = get_doctor_profile(doctor.get('ìƒì„¸ì •ë³´URL'), headers)
            doctor['profile'] = profile
            time.sleep(0.2)
            
        print(f"\nâœ… 3ë‹¨ê³„ ì™„ë£Œ: ëª¨ë“  ì •ë³´ í†µí•©. ìµœì¢… ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.")

        file_name = 'ì‚¼ì„±ì„œìš¸ë³‘ì›_smc'
        save_to_json(all_doctors, file_name)

        # 2. utils.pyì˜ í•¨ìˆ˜ë¥¼ ì´ìš©í•´ Excel íŒŒì¼ë¡œ ì €ì¥
        save_to_excel(all_doctors, file_name)